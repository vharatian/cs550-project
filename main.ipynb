{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import json\n", "import pickle\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import pandas as pd\n", "from tensorflow import keras\n", "from keras.models import Sequential\n", "from keras.layers import Dense\n", "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n", "from scipy.stats import zscore"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(42)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_compiled_model(experiment):\n", "    model = Sequential()\n", "    for _ in range(experiment.hidden_layer_count):\n", "        model.add(Dense(experiment.hidden_layer_units,\n", "                        activation=experiment.activation_method,\n", "                        kernel_initializer=experiment.initial_weights))\n", "    model.add(Dense(1,\n", "                    activation='sigmoid',\n", "                    kernel_initializer=experiment.initial_weights))\n", "    if experiment.optimizer_method == \"adam\":\n", "        opt = keras.optimizers.Adam(learning_rate=lr)\n", "    elif experiment.optimizer_method == \"sgd\":\n", "        opt = keras.optimizers.SGD(learning_rate=lr)\n", "    model.compile(\n", "        loss='binary_crossentropy',\n", "        optimizer=opt)\n", "    return model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def cross_val(experiment, X, y):\n", "    size = int(len(X) / experiment.folding_size)\n", "    total_acc = 0\n", "    for i in range(experiment.folding_size):\n", "        begin = size * i\n", "        end = size * (i + 1)\n", "        if i == experiment.folding_size - 1:\n", "            end = len(X)\n", "        X_val = X[begin:end]\n", "        y_val = y[begin:end]\n", "        X_train = np.concatenate((X[:begin], X[end:]), axis=0)\n", "        y_train = np.concatenate((y[:begin], y[end:]), axis=0)\n", "        model = get_compiled_model(experiment)\n", "        model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=experiment.epoch, verbose=0)\n", "        y_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n", "        total_acc += accuracy_score(y_val, y_pred)\n", "    avg_acc = total_acc / experiment.folding_size\n", "    return ExperimentResult(experiment, avg_acc)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def preprocess_bsl(df):\n", "    df = df.drop(\"SHA\", axis=1)\n", "    y = df.pop('defect').to_numpy().astype(int)\n", "    df = df.apply(zscore)\n", "    X = df.to_numpy().astype(\"float32\")\n", "    return X, y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class Experiment:\n", "    def __init__(self, folding_size, hidden_layer_count, hidden_layer_units, activation_method, optimizer_method,\n", "                 learning_rate, initial_weights, epoch):\n", "        self.initial_weights = initial_weights\n", "        self.optimizer_method = optimizer_method\n", "        self.activation_method = activation_method\n", "        self.folding_size = folding_size\n", "        self.epoch = epoch\n", "        self.learning_rate = learning_rate\n", "        self.hidden_layer_units = hidden_layer_units\n", "        self.hidden_layer_count = hidden_layer_count\n", "    def toJson(self):\n", "        return json.dumps(self, default=lambda o: o.__dict__,\n", "                          sort_keys=True, indent=4)\n", "    def __str__(self):\n", "        return self.toJson()\n", "    def __repr__(self):\n", "        return f\"{self}\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ExperimentResult:\n", "    def __init__(self, experiment, accuracy):\n", "        self.experiment = experiment\n", "        self.accuracy = accuracy\n", "    def toJson(self):\n", "        return json.dumps(self, default=lambda o: o.__dict__,\n", "                          sort_keys=True, indent=4)\n", "    def __str__(self):\n", "        return self.toJson()\n", "    def __repr__(self):\n", "        return f\"{self}\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class ExperimentResultGroup:\n", "    def __init__(self, group_name, results):\n", "        self.results = results\n", "        self.group_name = group_name"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def group_results(results, variable_name):\n", "    groups = []\n", "    for r in results:\n", "        variable_value = getattr(r.experiment, variable_name)\n", "        group = None\n", "        for g in groups:\n", "            if g.group_name == variable_value:\n", "                group = g\n", "                break\n", "        if group is None:\n", "            group = ExperimentResultGroup(variable_value, [])\n", "            groups += [group]\n", "        group.results += [r]\n", "    return groups"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('Datasets/baseline.csv')\n", "X, y = preprocess_bsl(df)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["best_acc = 0\n", "results = []\n", "# for num_hidden_layers in [1, 2, 3, 4]:\n", "for num_hidden_layers in [1]:\n", "    # for num_hidden_units in [1, 2, 4, 8]:\n", "    for num_hidden_units in [1]:\n", "        for lr in [0.1, 0.01, 0.001]:\n", "        # for lr in [0.1]:\n", "            for initial_weights in [\"glorot_normal\"]:\n", "                # for epochs in [200, 500]:\n", "                for epochs in [1, 2]:\n", "                    experiment = Experiment(50, num_hidden_layers, num_hidden_units, \"relu\", \"adam\", lr,\n", "                                            initial_weights, epochs)\n", "                    print(experiment)\n", "                    result = cross_val(experiment, X, y)\n", "                    results.append(result)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["results = [<br>\n", "    ExperimentResult(Experiment(1, None, None, None, None, None, None, 1), 0),<br>\n", "    ExperimentResult(Experiment(1, None, None, None, None, None, None, 2), 0.1),<br>\n", "    ExperimentResult(Experiment(1, None, None, None, None, None, None, 3), 0.2),<br>\n", "    ExperimentResult(Experiment(2, None, None, None, None, None, None, 1), 0.1),<br>\n", "    ExperimentResult(Experiment(2, None, None, None, None, None, None, 2), 0.2),<br>\n", "    ExperimentResult(Experiment(2, None, None, None, None, None, None, 3), 0.3),<br>\n", "    ExperimentResult(Experiment(3, None, None, None, None, None, None, 1), 0.2),<br>\n", "    ExperimentResult(Experiment(3, None, None, None, None, None, None, 2), 0.3),<br>\n", "    ExperimentResult(Experiment(3, None, None, None, None, None, None, 3), 0.4),<br>\n", "]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results.sort(key=lambda x: x.accuracy)\n", "plot_variables = [\"learning_rate\"]\n", "for pv in plot_variables:\n", "    groups = group_results(results, pv)\n", "    plt.title(pv)\n", "    plt.xlabel(\"Configurations\")\n", "    plt.ylabel(\"Accuracy\")\n", "    for g in groups:\n", "        x = list(range(len(g.results)))\n", "        y = [r.accuracy for r in g.results]\n", "        plt.plot(x, y, label=g.group_name)\n", "    plt.legend(loc='best')\n", "    plt.savefig(f\"plots/{pv}.png\")\n", "    plt.show()\n", "    plt.close()\n", "    plt.cla()\n", "    plt.clf()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["print(results)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}